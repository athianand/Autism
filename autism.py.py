# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15qDXftn7APiaico47x5GWjbwz6mGemTH
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data=pd.read_csv('/content/autism_screening.csv')

data.head()

data.columns

data.info()

data.describe()

data.shape

data.nunique

data.isnull().sum()

data['age'] = data['age'].fillna(round(data['age'].mean()))

data.isnull().sum()

data['contry_of_res'].unique()

df = ['gender', 'ethnicity', 'jundice', 'austim', 'contry_of_res', 'used_app_before', 'relation']

sns.countplot(data=data, x='Class/ASD')
plt.xlabel('Categories')
plt.ylabel('Count')
plt.title('Count of Autistic and Non-Autistic Patients')
plt.show()

sns.countplot(data=data, x='gender')
plt.xlabel('Categories')
plt.ylabel('Count')
plt.title('Count of Male and Female Patients')
plt.show()

g_vals = data['gender'].value_counts()
a_vals = data['Class/ASD'].value_counts()

fig, axes = plt.subplots(1, 2)  # create a grid with 1 row, 2 columns
fig.set_size_inches(8, 4)  # make the figure wide

# Create a pie chart in the first grid slot
axes[0].pie(g_vals, labels=['Male', 'Female'], startangle=90, autopct='%.1f%%')
axes[0].set_title('Patient Gender')

# Create a pie chart in the second grid slot
axes[1].pie(a_vals, labels=a_vals.index, startangle=90, autopct='%.1f%%')
axes[1].set_title('Count of Autistic and Non-Autistic Patients')

plt.show()

import plotly.express as px

# Count of Autistic Patients in Different Countries
Adata = data[data['Class/ASD'] == "YES"]
country_count = Adata['contry_of_res'].value_counts().reset_index()
country_count.columns = ['Country', 'Count']

# Create bar plot
plt = px.bar(country_count,
             x='Country',
             y='Count',
             title='Count of Autistic Patients in Different Countries')

# Update layout to center the title and set the category order
plt.update_layout(
    title_text='<b>Count of Autistic Patients in Different Countries</b>',
    title_x=0.5,
    xaxis=dict(categoryorder='total descending')
)

# Show the plot
plt.show()

import matplotlib.pyplot as plt

sns.countplot(data=data, x='jundice')
plt.xlabel('Categories')
plt.ylabel('Count')
plt.title('Count of Autistic and Non-Autistic Patients')
plt.show()

from sklearn.preprocessing import LabelEncoder

# Select the categorical columns for label encoding
categorical_cols = ['gender', 'ethnicity', 'jundice', 'austim', 'contry_of_res', 'used_app_before', 'relation', 'Class/ASD']

# Perform label encoding
encoder = LabelEncoder()
for col in categorical_cols:
    data[col] = encoder.fit_transform(data[col])

data.head()

data.shape

data = data.drop('age_desc', axis=1)

data.shape

X = data.drop('Class/ASD', axis=1)
y = data['Class/ASD']

X.shape , y.shape

# Splitting the dataset into train and test sets: 70-30 split
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size = 0.3, random_state = 12)
X_train.shape, y_train.shape, X_test.shape, y_test.shape

from sklearn.preprocessing import StandardScaler
from tensorflow.keras import layers, Sequential

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

model = Sequential([
    layers.Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], 1)),
    layers.MaxPooling1D(2),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(1, activation='linear')
])

model.summary()

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# # Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

loss_cnn, accuracy = model.evaluate(X_test, y_test)
# print('the loss and accurcay is', accuracy)

# # Evaluate the model
# loss_ddnn, accuracy_ddnn = model_ddnn.evaluate(X_test, y_test)
print(f'CNN: Loss: {loss_cnn}, Accuracy: {accuracy}')

predictions = model.predict(X_test)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Define the model architecture
model_ann = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

model_ann.summary()

# Compile the model
model_ann.compile(optimizer='adam',
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

# Train the model
history_ann = model_ann.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate the model
loss_ann, accuracy_ann = model_ann.evaluate(X_test, y_test)
print(f'ANN: Loss: {loss_ann}, Accuracy: {accuracy_ann}')

# Define the model architecture
model_ddnn = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

model_ddnn.summary()

# Compile the model
model_ddnn.compile(optimizer='adam',
                   loss='binary_crossentropy',
                   metrics=['accuracy'])

# Train the model
history_ddnn = model_ddnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate the model
loss_ddnn, accuracy_ddnn = model_ddnn.evaluate(X_test, y_test)
print(f'DDNN: Loss: {loss_ddnn}, Accuracy: {accuracy_ddnn}')

from tensorflow.keras.layers import SimpleRNN

# Reshape the input data for RNN
X_train_rnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test_rnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Define the model architecture
model_rnn = Sequential([
    SimpleRNN(64, input_shape=(X_train_rnn.shape[1], 1), activation='relu'),
    Dense(1, activation='sigmoid')
])

model_rnn.summary()

# Compile the model
model_rnn.compile(optimizer='adam',
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

history_rnn = model_rnn.fit(X_train_rnn, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate the model
loss_rnn, accuracy_rnn = model_rnn.evaluate(X_test_rnn, y_test)
print(f'RNN: Loss: {loss_rnn}, Accuracy: {accuracy_rnn}')

import pandas as pd

# Define the models and their corresponding accuracies
models = ['CNN','ANN', 'DDNN', 'RNN']
accuracies = [accuracy,accuracy_ann, accuracy_ddnn, accuracy_rnn]

# Create a pandas DataFrame
performance_table = pd.DataFrame({'Model': models, 'Accuracy': accuracies})

# Display the performance table
print(performance_table)

from sklearn.metrics import roc_curve, auc

# For RNN model
y_pred_proba_rnn = model_rnn.predict(X_test_rnn)

# For DDNN model
y_pred_proba_ddnn = model_ddnn.predict(X_test)

# For CNN model
y_pred_proba_cnn = model.predict(X_test)

# For ANN model
y_pred_proba_ann = model_ann.predict(X_test)

# Compute ROC curve and AUC score for each model
fpr_cnn, tpr_cnn, _ = roc_curve(y_test, y_pred_proba_cnn)
roc_auc_cnn = auc(fpr_cnn, tpr_cnn)

fpr_ann, tpr_ann, _ = roc_curve(y_test, y_pred_proba_ann)
roc_auc_ann = auc(fpr_ann, tpr_ann)

fpr_ddnn, tpr_ddnn, _ = roc_curve(y_test, y_pred_proba_ddnn)
roc_auc_ddnn = auc(fpr_ddnn, tpr_ddnn)

fpr_rnn, tpr_rnn, _ = roc_curve(y_test, y_pred_proba_rnn)
roc_auc_rnn = auc(fpr_rnn, tpr_rnn)

# Plot ROC curve for each model
plt.figure(figsize=(8, 6))
plt.plot(fpr_cnn, tpr_cnn, label=f'CNN (AUC = {roc_auc_cnn:.2f})')
plt.plot(fpr_ann, tpr_ann, label=f'ANN (AUC = {roc_auc_ann:.2f})')
plt.plot(fpr_ddnn, tpr_ddnn, label=f'DDNN (AUC = {roc_auc_ddnn:.2f})')
plt.plot(fpr_rnn, tpr_rnn, label=f'RNN (AUC = {roc_auc_rnn:.2f})')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guess')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

import pickle

# As the performance model_rnn is the best model
best_model = model_rnn

# Save the model to a file
with open('best_model.pkl', 'wb') as f:
    pickle.dump(best_model, f)